[Global]
epoch=30
batch_size=24
tau=0.8
grad_norm=5.0
pretrained_grad_norm=1.0
early_stopping={ metric=['seg_f1','pos_acc','ner_f1','dep_LAS','sdp_f1','srl_f1'] }

[[Task]]
name='seg'
config='config/ltp_base/seg.toml'

[[Task]]
name='pos'
config='config/ltp_base/pos.toml'

[[Task]]
name='ner'
config='config/ltp_base/ner.toml'

[[Task]]
name='dep'
config='config/ltp_base/dep.toml'

[[Task]]
name='sdp'
config='config/ltp_base/sdp.toml'

[[Task]]
name='srl'
config='config/ltp_base/srl.toml'

[Loss]
class = "kd_ce_loss"

[Optimizer]
class = "BertAdamW4CRF"
    [Optimizer.init]
    lr = 1e-4
    crf_lr = 1e-3
    bert_lr = 1e-4

[Scheduler]
class = "LinearLRW"
type = 'step'
warmup_proportion=0.002

[Checkpoint]
directory="checkpoint/ltp_tiny/distill"
plugins=['best','restore']
best={ metric=['seg_f1','pos_acc','ner_f1','dep_LAS','sdp_f1','srl_f1'] }

[Trainer]
class = 'multi_dist'
  [Trainer.init]
  temperature=8

[TemperatureScheduler]
class = 'flsw'

[Model]
class = "SimpleMultiTaskModel"

    [Model.init]
    pretrained="data/electra_tiny"
    [Model.init.seg]
    label_num=2
    [Model.init.pos]
    label_num=27
    word_base=true
    [Model.init.ner]
    label_num=13
    word_base=true
    decoder="RelativeTransformer"
    [Model.init.ner.RelativeTransformer]
    num_heads=4
    num_layers=2
    hidden_size=256
    [Model.init.dep]
    label_num=14
    decoder="Graph"
    use_cls=true
    word_base=true
    [Model.init.dep.Graph]
    arc_hidden_size=100
    rel_hidden_size=128
    [Model.init.sdp]
    label_num=59
    decoder="Graph"
    word_base=true
    use_cls=true
    [Model.init.sdp.Graph]
    arc_hidden_size=100
    rel_hidden_size=128
    [Model.init.srl]
    label_num=97
    decoder="BiLinearCRF"
    word_base=true
    [Model.init.srl.BiLinearCRF]
    hidden_size=128
    dropout=0.2

